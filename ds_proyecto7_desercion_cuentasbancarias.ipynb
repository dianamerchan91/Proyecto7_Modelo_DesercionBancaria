{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de análisis predictivo para determinar clientes con tendencia a la deserción en Beta Bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de Contenidos<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introducción\" data-toc-modified-id=\"Introducción-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introducción</a></span><ul class=\"toc-item\"><li><span><a href=\"#Objetivos\" data-toc-modified-id=\"Objetivos-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Objetivos</a></span></li></ul></li><li><span><a href=\"#Inicialización\" data-toc-modified-id=\"Inicialización-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Inicialización</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cargar-datos\" data-toc-modified-id=\"Cargar-datos-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Cargar datos</a></span></li><li><span><a href=\"#Explorar-datos-iniciales\" data-toc-modified-id=\"Explorar-datos-iniciales-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Explorar datos iniciales</a></span></li><li><span><a href=\"#Visualización-de-datos\" data-toc-modified-id=\"Visualización-de-datos-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Visualización de datos</a></span></li><li><span><a href=\"#Conclusiones\" data-toc-modified-id=\"Conclusiones-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Conclusiones</a></span></li></ul></li><li><span><a href=\"#Preprocesamiento-de-datos\" data-toc-modified-id=\"Preprocesamiento-de-datos-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Preprocesamiento de datos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Corrección-nombre-de-las-columnas\" data-toc-modified-id=\"Corrección-nombre-de-las-columnas-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Corrección nombre de las columnas</a></span></li><li><span><a href=\"#Eliminación-de-columnas\" data-toc-modified-id=\"Eliminación-de-columnas-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Eliminación de columnas</a></span></li><li><span><a href=\"#Corrección-valores-ausentes-en-tenure\" data-toc-modified-id=\"Corrección-valores-ausentes-en-tenure-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Corrección valores ausentes en <code>tenure</code></a></span></li><li><span><a href=\"#Conclusiones\" data-toc-modified-id=\"Conclusiones-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Conclusiones</a></span></li></ul></li><li><span><a href=\"#Estandarización-y-segmentación-de-datos-fuente\" data-toc-modified-id=\"Estandarización-y-segmentación-de-datos-fuente-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Estandarización y segmentación de datos fuente</a></span><ul class=\"toc-item\"><li><span><a href=\"#Estandarización-de-características-numéricas\" data-toc-modified-id=\"Estandarización-de-características-numéricas-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Estandarización de características numéricas</a></span></li><li><span><a href=\"#Segmentación-de-datos\" data-toc-modified-id=\"Segmentación-de-datos-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Segmentación de datos</a></span></li></ul></li><li><span><a href=\"#Desequilibrio-de-clases\" data-toc-modified-id=\"Desequilibrio-de-clases-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Desequilibrio de clases</a></span></li><li><span><a href=\"#Modelos-sin-desequilibrio-de-clases\" data-toc-modified-id=\"Modelos-sin-desequilibrio-de-clases-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Modelos sin desequilibrio de clases</a></span><ul class=\"toc-item\"><li><span><a href=\"#Árbol-de-Decisión\" data-toc-modified-id=\"Árbol-de-Decisión-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Árbol de Decisión</a></span></li><li><span><a href=\"#Bosque-Aleatorio\" data-toc-modified-id=\"Bosque-Aleatorio-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Bosque Aleatorio</a></span></li><li><span><a href=\"#Regresión-Logística\" data-toc-modified-id=\"Regresión-Logística-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Regresión Logística</a></span></li><li><span><a href=\"#Conclusiones\" data-toc-modified-id=\"Conclusiones-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Conclusiones</a></span></li></ul></li><li><span><a href=\"#Modelos-con-desequilibrio-de-clases\" data-toc-modified-id=\"Modelos-con-desequilibrio-de-clases-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Modelos con desequilibrio de clases</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sobremuestreo\" data-toc-modified-id=\"Sobremuestreo-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Sobremuestreo</a></span></li><li><span><a href=\"#Submuestreo\" data-toc-modified-id=\"Submuestreo-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Submuestreo</a></span></li><li><span><a href=\"#Ajuste-de-peso-de-clase\" data-toc-modified-id=\"Ajuste-de-peso-de-clase-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Ajuste de peso de clase</a></span></li><li><span><a href=\"#Conclusiones\" data-toc-modified-id=\"Conclusiones-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>Conclusiones</a></span></li></ul></li><li><span><a href=\"#Prueba-Final:-Calidad-del-modelo\" data-toc-modified-id=\"Prueba-Final:-Calidad-del-modelo-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Prueba Final: Calidad del modelo</a></span></li><li><span><a href=\"#Prueba-de-Cordura\" data-toc-modified-id=\"Prueba-de-Cordura-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Prueba de Cordura</a></span></li><li><span><a href=\"#Conclusiones\" data-toc-modified-id=\"Conclusiones-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Conclusiones</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En los últimos meses la entidad bancaria Beta Bank está reportando una pérdida sustancial de clientes, los cuales están abandonando sus cuentas bancarias paulatinamente. Estos clientes que dejan de utilizar los servicios de una empresa se conocen como desertores, y la cancelación de sus cuentas puede estar relacionada con un mal servicio por parte del banco u ofertas más asequibles por parte de competencia. Considerando esto, y que resulta más costoso atraer nuevos clientes que salvar a los clientes existentes, Beta Bank ha decidido buscar estrategias que garanticen la retención y la disminución de la deserción de clientes antiguos.\n",
    "\n",
    "Una de estas estrategias es la generación de modelos predictivos que permitan establecer aquellos desertores o clientes que están muy cerca de abandonar sus cuentas bancarias. Es así que Beta Bank, ha decidido generar un modelo de machine learning que a partir de datos sobre el comportamiento pasado de sus clientes y la terminación de contratos con el banco, buscará establecer qué clientes son más propensos a desvincularse de la empresa. En este proyecto se comparará diferentes modelos de machine learning y se escogerá aquel modelo que presente un valor F1 de al menos 0.59.\n",
    "\n",
    "### Objetivos\n",
    "\n",
    "1. Crear un modelo de machine learning que permita determinar aquellos clientes con una mayor tendencia a abandonar sus cuentas bancarias en Beta Bank. \n",
    "2. Examinar el equilibrio de clases y entrenar modelos que no consideren el desequilibrio de clases. \n",
    "3. Entrenar diferentes modelos de machine learning, escoger aquel modelo con el máximo valor F1 posible (al menos 0.59) y medir AUC-ROC en todos los modelos entrenados. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialización\n",
    "\n",
    "Empezamos importando todas las librerías necesarias para desarrollar el mejor modelo de machine learning. En este caso, trabajaremos con la librería `Pandas`, `Numpy` y `Scikit-Learn`, las cuales permiten leer correctamente los archivos, trabajar con datos y generar diferentes tipos de modelos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar datos\n",
    "\n",
    "A continuacion, vamos a importar el archivo con la información relacionada al comportamiento pasado de clientes de Beta Bank. Para esto, utilizaremos la función `pd.read_csv` de pandas y pasaremos como argumento la ubicación del archivo. Guardaremos nuestro dataset dentro de la variable `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorar datos iniciales\n",
    "\n",
    "Una vez importado nuestro dataset con la información de cada cliente de Beta Bank, procedemos a realizar una exploración de los datos. Iniciamos llamando a los métodos `head`, `tail`, `info` y al atributo `shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "9995     5.0       0.00              2          1               0   \n",
       "9996    10.0   57369.61              1          1               1   \n",
       "9997     7.0       0.00              1          0               1   \n",
       "9998     3.0   75075.31              2          1               0   \n",
       "9999     NaN  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro dataset `data` cuenta con 10000 filas y 14 columnas, las cuales presentan la siguiente información:\n",
    "\n",
    "- `RowNumber`: índice de cadena de datos\n",
    "- `CustomerId`: identificador de cliente único\n",
    "- `Surname`: apellido\n",
    "- `CreditScore`: valor de crédito\n",
    "- `Geography:` país de residencia\n",
    "- `Gender`: sexo\n",
    "- `Age`: edad\n",
    "- `Tenure`: período durante el cual ha madurado el depósito a plazo fijo de un cliente (años)\n",
    "- `Balance`: saldo de la cuenta\n",
    "- `NumOfProducts`: número de productos bancarios utilizados por el cliente\n",
    "- `HasCrCard`: el cliente tiene una tarjeta de crédito (1 - sí; 0 - no)\n",
    "- `IsActiveMember`: actividad del cliente (1 - sí; 0 - no)\n",
    "- `EstimatedSalary`: salario estimado\n",
    "- `Exited`: El cliente se ha ido (1 - sí; 0 - no)\n",
    "\n",
    "Cada fila corresponde a una observación en la construcción de nuestro modelo de machine learning, es decir se cuenta con el comportamiento de 10000 usuarios de Beta Bank. La columna `Exited` será el objetivo de nuestro modelo, ya que alberga la información sobre si el cliente ha abandonado o no la entidad bancaria, y las trece columnas restantes corresponderían a las características del modelo, a partir de las cuales se entrenará el modelo predictivo. \n",
    "\n",
    "Se puede observar algunos problemas dentro de nuestros datos que requieren una corrección. En primer lugar, el nombre de las columnas se encuentra en mayúsculas, por lo que será necesario tranformar todo a minúsculas para mantener las reglas del buen estilo en programación. En segundo lugar, podemos observar la presencia de valores ausentes en la columna `Tenure`, estos valores requieren ser rellenados. A su vez, los valores de años en `Tenure` se presentan como tipo float, cuando deberían presentarse como tipo entero. \n",
    "\n",
    "Las columnas `RowNumber`, `CustomerId` y `Surname` contienen información sobre la identificación y apellido de cada cliente, lo cual no va a ser útil para nuestro modelo predictivo, así que será necesario eliminar estas variables. \n",
    "\n",
    "Analicemos más de cerca los valores ausentes y duplicados de nuestro dataset, llamemos a los métodos `isna`, `duplicated` y `sum` en nuestro dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber            0\n",
       "CustomerId           0\n",
       "Surname              0\n",
       "CreditScore          0\n",
       "Geography            0\n",
       "Gender               0\n",
       "Age                  0\n",
       "Tenure             909\n",
       "Balance              0\n",
       "NumOfProducts        0\n",
       "HasCrCard            0\n",
       "IsActiveMember       0\n",
       "EstimatedSalary      0\n",
       "Exited               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de valores ausentes: 9.09\n"
     ]
    }
   ],
   "source": [
    "print('Porcentaje de valores ausentes:', data['Tenure'].isna().sum()*100/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se mencionó anteriomente solo se registran valores ausentes en la columna `Tenure`, los cuales requieren ser rellenados ya que representan el 9.09% de nuestro dataset. No se registran valores duplicados en nuestro conjunto de datos, así que continuaremos con el análisis de las variables continuas y discretas. \n",
    "\n",
    "### Visualización de datos\n",
    "\n",
    "En nuestros datos se pueden observar nueve variables discretas y cinco variables continuas. A continuación vamos a generar gráficos que nos permitan visualizar la distribución de nuestros datos dentro de cada una de estas variables. No consideraremos las variables `RowNumber`, `CustomerId` y `Surname`, ya que solo albergan la identificación o apellido de cada usuario, y no sería pertinente trazar estos gráficos. \n",
    "\n",
    "Construimos dos bucles for que nos devuelven gráficos de barras para cada variable discreta, llamamos a value_counts para obtener el recuento de valores únicos de cada categoría y utilizamos el parámetro normalize=True para obtener una distribución relativa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x864 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Almacenamos a las variables discretas en la variable categorical_data\n",
    "categorical_data= ['Geography', 'Gender', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'Exited', 'Tenure']\n",
    "\n",
    "# Establecemos el número de filas y columnas para nuestros subplots\n",
    "a = 3 # número de filas\n",
    "b = 3 # número de columnas\n",
    "c = 1 # inicialización del conteo de plots\n",
    "\n",
    "# Establecemos el tamaño de nuestra figura de subplots\n",
    "fig = plt.subplots(figsize=(18, 12)) \n",
    "\n",
    "# Construimos un bucle for que iterará por cada columna categórica y devolverá un gráfico de barras\n",
    "for i in categorical_data:\n",
    "    plt.subplot(a, b, c)\n",
    "    plt.title(i)\n",
    "    plt.ylabel('%')\n",
    "    data[i].value_counts(normalize=True).plot(kind='bar', title=i, rot=0)\n",
    "    c = c + 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al analizar las variables discretas podemos observar un mayor porcentaje de usuarios de Francia, que representan cerca del 50% de clientes en Beta Bank, seguidos de Alemania y España. A su vez, Hay un mayor porcentaje de hombres que mujeres, representando más del 50% del total de usuarios. Por otro lado, La mayoría de usuarios utilizan entre 1 a 2 productos bancarios, mientras que aquellos clientes que usan de 3 a 4 productos son más bien escasos. \n",
    "\n",
    "Cerca del 70% de usuarios tienen acceso a una tarjeta de crédito y el 30% no registran una tarjeta. Existe una distribución más o menos similar en relación a la actividad del cliente, presentando un mayor porcentaje de clientes activos, aunque no se observan diferencias grandes entre ambas categorías. En cuanto a la variable `Exited` se observa una diferencia notable entre las dos categorías, con un 20% de usuarios desertores y más del 70% de usuarios que aún conservan sus cuentas bancarias. \n",
    "\n",
    "En el caso de `Tenure` decidimos trazar un gráfico de barras, ya que un histograma no nos ayudará a representar la distribución correcta de esta variable. Se puede observar una distribución similar, con más del 8% de clientes que mantienen depósitos a plazos fijos entre los uno a nueve años, y existen menos clientes con depósitos a plazos fijos de 0 y 10 años. \n",
    "\n",
    "Ahora procedemos a analizar las variables continuas, primero aplicaremos el método describe a las variables para observar la distribución de los datos y posteriormente trazaremos histogramas de frecuencia a través de un bucle for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9091.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>4.997690</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>100090.239881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.894723</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>57510.492818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CreditScore           Age       Tenure        Balance  NumOfProducts  \\\n",
       "count  10000.000000  10000.000000  9091.000000   10000.000000   10000.000000   \n",
       "mean     650.528800     38.921800     4.997690   76485.889288       1.530200   \n",
       "std       96.653299     10.487806     2.894723   62397.405202       0.581654   \n",
       "min      350.000000     18.000000     0.000000       0.000000       1.000000   \n",
       "25%      584.000000     32.000000     2.000000       0.000000       1.000000   \n",
       "50%      652.000000     37.000000     5.000000   97198.540000       1.000000   \n",
       "75%      718.000000     44.000000     7.000000  127644.240000       2.000000   \n",
       "max      850.000000     92.000000    10.000000  250898.090000       4.000000   \n",
       "\n",
       "       EstimatedSalary  \n",
       "count     10000.000000  \n",
       "mean     100090.239881  \n",
       "std       57510.492818  \n",
       "min          11.580000  \n",
       "25%       51002.110000  \n",
       "50%      100193.915000  \n",
       "75%      149388.247500  \n",
       "max      199992.480000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_data = data[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']]\n",
    "numerical_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Almacenamos a las variables discretas en la variable numerical_data_1\n",
    "numerical_data_1= ['CreditScore', 'Age', 'Balance', 'EstimatedSalary']\n",
    "\n",
    "# Establecemos el número de filas y columnas para nuestros subplots\n",
    "a = 2 # número de filas\n",
    "b = 2 # número de columnas\n",
    "c = 1 # inicialización del conteo de plots\n",
    "\n",
    "# Establecemos el tamaño de nuestra figura de subplots\n",
    "fig = plt.subplots(figsize=(16, 8)) \n",
    "\n",
    "# Construimos un bucle for que iterará por cada columna numérica y devolverá un histograma\n",
    "for i in numerical_data_1:\n",
    "    plt.subplot(a, b, c)\n",
    "    plt.title(i)\n",
    "    data[i].plot(kind='hist', title=i, bins=15)\n",
    "    c = c + 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para variable `CreditScore` podemos observar una mediana mayor a la media, lo que indica una asimetría negativa con una mayor cantidad de valores a la izquierda del pico más alto, esto se hace evidente al trazar el histograma de frecuencias, en el cual observamos un mayor número de clientes presentan entre 600 a 700 como valor de crédito, y hacia la izquierda del pico observamos menos clientes con créditos inferiores a 500.\n",
    "\n",
    "En el caso de la variable `Age` podemos observar una media mayor a la mediana, lo que indica una asimetría positiva o un sesgo hacia la derecha de los datos. Esto se puede evidenciar en nuestro histograma de frecuencia con el pico más alto alrededor de los 35 años, y luego a la derecha del pico se observa un cola larga que confirma el sesgo detectado anteriormente. \n",
    "\n",
    "Al analizar la variable `Balance` nos encontramos con un comportamiento extraño en nuestros datos, con el pico más alto del histograma cerca de cero, posteriormente se vuelve a observar un nuevo pico alrededor de 100000. A su vez, se puede observar una media menor a la mediana, lo que nos permite establecer una asimetría negativa con un mayor número de datos a la izquierda del pico más alto. También podemos observar una alta desviación estándar, que confirma la presencia de valores atípicos, esto también se hace evidente en la diferencia entre la media y la mediana, haciendo que la media sea más susceptible a los cambios producidos por estos valores. Vamos a mantener estos valores atípicos ya que podrían estar relacionados con aquellos clientes que han abandonado el banco y nos servirá para construir nuestro modelo. \n",
    "\n",
    "Para la variable `EstimatedSalary` encontramos una distribución similar de clientes entre los diferentes salarios, con una mediana ligeramente superior a la media, lo que indicaría un sesgo a la izquierda en nuestros datos. \n",
    "\n",
    "Finalmente, vamos a analizar la correlación entre las diferentes variables de este proyecto, poniendo énfasis en la correlación entre las características y objetivo para la posterior construcción de nuestro modelo. Llamamos entonces a la función corr()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.005840</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>-0.007322</td>\n",
       "      <td>-0.009067</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.012044</td>\n",
       "      <td>-0.005988</td>\n",
       "      <td>-0.016571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerId</th>\n",
       "      <td>0.004202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>-0.021418</td>\n",
       "      <td>-0.012419</td>\n",
       "      <td>0.016972</td>\n",
       "      <td>-0.014025</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.015271</td>\n",
       "      <td>-0.006248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreditScore</th>\n",
       "      <td>0.005840</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003965</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>-0.005458</td>\n",
       "      <td>0.025651</td>\n",
       "      <td>-0.001384</td>\n",
       "      <td>-0.027094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>-0.003965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.013134</td>\n",
       "      <td>0.028308</td>\n",
       "      <td>-0.030680</td>\n",
       "      <td>-0.011721</td>\n",
       "      <td>0.085472</td>\n",
       "      <td>-0.007201</td>\n",
       "      <td>0.285323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tenure</th>\n",
       "      <td>-0.007322</td>\n",
       "      <td>-0.021418</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-0.013134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007911</td>\n",
       "      <td>0.011979</td>\n",
       "      <td>0.027232</td>\n",
       "      <td>-0.032178</td>\n",
       "      <td>0.010520</td>\n",
       "      <td>-0.016761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balance</th>\n",
       "      <td>-0.009067</td>\n",
       "      <td>-0.012419</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>0.028308</td>\n",
       "      <td>-0.007911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.304180</td>\n",
       "      <td>-0.014858</td>\n",
       "      <td>-0.010084</td>\n",
       "      <td>0.012797</td>\n",
       "      <td>0.118533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumOfProducts</th>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.016972</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>-0.030680</td>\n",
       "      <td>0.011979</td>\n",
       "      <td>-0.304180</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.009612</td>\n",
       "      <td>0.014204</td>\n",
       "      <td>-0.047820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasCrCard</th>\n",
       "      <td>0.000599</td>\n",
       "      <td>-0.014025</td>\n",
       "      <td>-0.005458</td>\n",
       "      <td>-0.011721</td>\n",
       "      <td>0.027232</td>\n",
       "      <td>-0.014858</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011866</td>\n",
       "      <td>-0.009933</td>\n",
       "      <td>-0.007138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsActiveMember</th>\n",
       "      <td>0.012044</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.025651</td>\n",
       "      <td>0.085472</td>\n",
       "      <td>-0.032178</td>\n",
       "      <td>-0.010084</td>\n",
       "      <td>0.009612</td>\n",
       "      <td>-0.011866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011421</td>\n",
       "      <td>-0.156128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <td>-0.005988</td>\n",
       "      <td>0.015271</td>\n",
       "      <td>-0.001384</td>\n",
       "      <td>-0.007201</td>\n",
       "      <td>0.010520</td>\n",
       "      <td>0.012797</td>\n",
       "      <td>0.014204</td>\n",
       "      <td>-0.009933</td>\n",
       "      <td>-0.011421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exited</th>\n",
       "      <td>-0.016571</td>\n",
       "      <td>-0.006248</td>\n",
       "      <td>-0.027094</td>\n",
       "      <td>0.285323</td>\n",
       "      <td>-0.016761</td>\n",
       "      <td>0.118533</td>\n",
       "      <td>-0.047820</td>\n",
       "      <td>-0.007138</td>\n",
       "      <td>-0.156128</td>\n",
       "      <td>0.012097</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 RowNumber  CustomerId  CreditScore       Age    Tenure  \\\n",
       "RowNumber         1.000000    0.004202     0.005840  0.000783 -0.007322   \n",
       "CustomerId        0.004202    1.000000     0.005308  0.009497 -0.021418   \n",
       "CreditScore       0.005840    0.005308     1.000000 -0.003965 -0.000062   \n",
       "Age               0.000783    0.009497    -0.003965  1.000000 -0.013134   \n",
       "Tenure           -0.007322   -0.021418    -0.000062 -0.013134  1.000000   \n",
       "Balance          -0.009067   -0.012419     0.006268  0.028308 -0.007911   \n",
       "NumOfProducts     0.007246    0.016972     0.012238 -0.030680  0.011979   \n",
       "HasCrCard         0.000599   -0.014025    -0.005458 -0.011721  0.027232   \n",
       "IsActiveMember    0.012044    0.001665     0.025651  0.085472 -0.032178   \n",
       "EstimatedSalary  -0.005988    0.015271    -0.001384 -0.007201  0.010520   \n",
       "Exited           -0.016571   -0.006248    -0.027094  0.285323 -0.016761   \n",
       "\n",
       "                  Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "RowNumber       -0.009067       0.007246   0.000599        0.012044   \n",
       "CustomerId      -0.012419       0.016972  -0.014025        0.001665   \n",
       "CreditScore      0.006268       0.012238  -0.005458        0.025651   \n",
       "Age              0.028308      -0.030680  -0.011721        0.085472   \n",
       "Tenure          -0.007911       0.011979   0.027232       -0.032178   \n",
       "Balance          1.000000      -0.304180  -0.014858       -0.010084   \n",
       "NumOfProducts   -0.304180       1.000000   0.003183        0.009612   \n",
       "HasCrCard       -0.014858       0.003183   1.000000       -0.011866   \n",
       "IsActiveMember  -0.010084       0.009612  -0.011866        1.000000   \n",
       "EstimatedSalary  0.012797       0.014204  -0.009933       -0.011421   \n",
       "Exited           0.118533      -0.047820  -0.007138       -0.156128   \n",
       "\n",
       "                 EstimatedSalary    Exited  \n",
       "RowNumber              -0.005988 -0.016571  \n",
       "CustomerId              0.015271 -0.006248  \n",
       "CreditScore            -0.001384 -0.027094  \n",
       "Age                    -0.007201  0.285323  \n",
       "Tenure                  0.010520 -0.016761  \n",
       "Balance                 0.012797  0.118533  \n",
       "NumOfProducts           0.014204 -0.047820  \n",
       "HasCrCard              -0.009933 -0.007138  \n",
       "IsActiveMember         -0.011421 -0.156128  \n",
       "EstimatedSalary         1.000000  0.012097  \n",
       "Exited                  0.012097  1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar correlaciones cercanas a cero para la mayoría de variables, lo cual indica que las variables están correlacionadas pero no a través de una correlación lineal. Hay que destacar la correlación entre nuestro objetivo `Exited` y la característica `Age`, con una correlación positiva de 0.28, que indica que la edad puede ser un factor que influye en cierta medida la deserción de los clientes. También encontramos una correlación positiva de 0.11 entre `Exited` y `Balance`, mientras que se puede evidenciar una correlación negativa entre `Exited` y la actividad de un cliente `IsActiveMember`.\n",
    "\n",
    "### Conclusiones\n",
    "\n",
    "1. Se registraron valores ausentes en la columna `Tenure` los cuales requieren ser correctamente rellenados para la posterior construcción de nuestro modelo. A su vez, los valores de esta variable se encuentra como tipo float, siendo más conveniente registrarlos como tipo entero. \n",
    "2. No se registraron valores duplicados dentro de nuestro dataset. \n",
    "3. Existen tres variables `RowNumber`, `CustomerId` y `Surname` que albergan información relacionada con la ID del usuario o su apellido, considerando que esta información no influirá en si un cliente abandona el banco, lo más conveniente será eliminarlas. \n",
    "4. Los nombres de la columnas se encuentran en mayúsculas, será conveniente transformarlas a minúsculas para cumplir con las reglas del buen estilo de programación. \n",
    "5. Al analizar nuetras variables discretas nos encontramos que la mayoría de clientes de Beta Bank pertenecen a Francia, existe una proporción mayo de hombre que mujeres, y un mayor porcentaje utiliza entre 1 a 2 productos bancarios. A su vez, hay un mayor porcentaje de clientes con tarjetas de crédito y más del 70% de clientes no han abandonado sus cuentas bancarias. Sin embargo, existe una proporción similar entre clientes activos y no. \n",
    "6. En cuanto a las variables continuas, encontramos una mayor proporción de clientes con 600 a 700 créditos, que se encuentran entre los 30 a 40 años. Existe un alto número de clientes con un balance de cero en sus cuentas bancarias, estos valores atípicos decididimos mantenerlos ya que podrían estar relacionados con la deserción de clientes. Para el salario estimado y el período de duración de un depósito se observó una distribución similar. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos\n",
    "\n",
    "### Corrección nombre de las columnas \n",
    "\n",
    "Como se mencionó anteriormente será necesario corregir el nombre de las columnas y transfomar todo en minúsculas. Primero llamaremos a columns en nuestro dataset `data` para observar el nombre de las columnas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
       "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pueden observar nombres de columnas con mayúsculas, vamos a transformar los nombres en minúsculas con la función str.lower(), y previamente vamos a añadir guiones bajos para separar aquellos nombres que presentan varias palabras, así se facilitará su lectura. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row_number', 'customer_id', 'surname', 'credit_score', 'geography',\n",
       "       'gender', 'age', 'tenure', 'balance', 'num_of_products', 'has_cr_card',\n",
       "       'is_active_member', 'estimated_salary', 'exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cambiamos el nombre de las columnas llamando a la función rename\n",
    "data = data.rename(\n",
    "    columns = {'RowNumber' : 'row_number', \n",
    "              'CustomerId' : 'customer_id',\n",
    "              'CreditScore' : 'credit_score',\n",
    "              'NumOfProducts' : 'num_of_products',\n",
    "              'HasCrCard' : 'has_cr_card',\n",
    "              'IsActiveMember' : 'is_active_member',\n",
    "              'EstimatedSalary': 'estimated_salary'\n",
    "               }\n",
    ")\n",
    "\n",
    "# Transformamos todos los nombres a minúsculas\n",
    "data.columns = data.columns.str.lower()\n",
    "\n",
    "# Comprobamos los nuevos nombres de columnas \n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de columnas \n",
    "\n",
    "Al realizar un análisis exploratorio de los datos nos encontramos con tres columnas que no serán importantes para construir nuestro modelo predictivo. `row_number` solo alberga el índice de cadena de datos, `customer_id` guarda el id de cada usuario del banco y `surname` el apellido, información que no será necesaria, así que vamos a continuar con nuestros análisis sin considerar estas columnas. Aplicamos la función drop a nuestro dataset y pasamos como argumentos los nombres de estas tres variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   credit_score      10000 non-null  int64  \n",
      " 1   geography         10000 non-null  object \n",
      " 2   gender            10000 non-null  object \n",
      " 3   age               10000 non-null  int64  \n",
      " 4   tenure            9091 non-null   float64\n",
      " 5   balance           10000 non-null  float64\n",
      " 6   num_of_products   10000 non-null  int64  \n",
      " 7   has_cr_card       10000 non-null  int64  \n",
      " 8   is_active_member  10000 non-null  int64  \n",
      " 9   estimated_salary  10000 non-null  float64\n",
      " 10  exited            10000 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(columns=['row_number', 'customer_id', 'surname'])\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrección valores ausentes en `tenure`\n",
    "\n",
    "Para rellenar los valores ausentes de la variable `tenure` vamos a analizar más a detalle si existe algún patrón subyacente que está determinando la presencia de estos valores. Para esto vamos a comparar las frecuencias relativas de todas las variables en nuestro dataset con valores ausentes `data` y sin valores ausentes `data_no_nan`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850    0.0233\n",
      "678    0.0063\n",
      "655    0.0054\n",
      "667    0.0053\n",
      "705    0.0053\n",
      "        ...  \n",
      "412    0.0001\n",
      "351    0.0001\n",
      "365    0.0001\n",
      "373    0.0001\n",
      "423    0.0001\n",
      "Name: credit_score, Length: 460, dtype: float64\n",
      "France     0.5014\n",
      "Germany    0.2509\n",
      "Spain      0.2477\n",
      "Name: geography, dtype: float64\n",
      "Male      0.5457\n",
      "Female    0.4543\n",
      "Name: gender, dtype: float64\n",
      "37    0.0478\n",
      "38    0.0477\n",
      "35    0.0474\n",
      "36    0.0456\n",
      "34    0.0447\n",
      "       ...  \n",
      "92    0.0002\n",
      "88    0.0001\n",
      "82    0.0001\n",
      "85    0.0001\n",
      "83    0.0001\n",
      "Name: age, Length: 70, dtype: float64\n",
      "1.0     0.0952\n",
      "2.0     0.0950\n",
      "8.0     0.0933\n",
      "3.0     0.0928\n",
      "5.0     0.0927\n",
      "7.0     0.0925\n",
      "NaN     0.0909\n",
      "4.0     0.0885\n",
      "9.0     0.0882\n",
      "6.0     0.0881\n",
      "10.0    0.0446\n",
      "0.0     0.0382\n",
      "Name: tenure, dtype: float64\n",
      "0.00         0.3617\n",
      "105473.74    0.0002\n",
      "130170.82    0.0002\n",
      "72594.00     0.0001\n",
      "139723.90    0.0001\n",
      "              ...  \n",
      "130306.49    0.0001\n",
      "92895.56     0.0001\n",
      "132005.77    0.0001\n",
      "166287.85    0.0001\n",
      "104001.38    0.0001\n",
      "Name: balance, Length: 6382, dtype: float64\n",
      "1    0.5084\n",
      "2    0.4590\n",
      "3    0.0266\n",
      "4    0.0060\n",
      "Name: num_of_products, dtype: float64\n",
      "1    0.7055\n",
      "0    0.2945\n",
      "Name: has_cr_card, dtype: float64\n",
      "1    0.5151\n",
      "0    0.4849\n",
      "Name: is_active_member, dtype: float64\n",
      "24924.92     0.0002\n",
      "109145.20    0.0001\n",
      "59755.14     0.0001\n",
      "1557.82      0.0001\n",
      "117202.19    0.0001\n",
      "              ...  \n",
      "37674.47     0.0001\n",
      "158043.11    0.0001\n",
      "103792.53    0.0001\n",
      "182266.01    0.0001\n",
      "155061.97    0.0001\n",
      "Name: estimated_salary, Length: 9999, dtype: float64\n",
      "0    0.7963\n",
      "1    0.2037\n",
      "Name: exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Construimos un bucle for que devuelva la distribución relativa de cada variable. \n",
    "for col in data:\n",
    "    print(data[col].value_counts(normalize=True, dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850    0.02310\n",
      "678    0.00660\n",
      "655    0.00561\n",
      "705    0.00528\n",
      "683    0.00517\n",
      "        ...   \n",
      "382    0.00011\n",
      "351    0.00011\n",
      "367    0.00011\n",
      "383    0.00011\n",
      "376    0.00011\n",
      "Name: credit_score, Length: 458, dtype: float64\n",
      "France     0.500495\n",
      "Germany    0.252227\n",
      "Spain      0.247278\n",
      "Name: geography, dtype: float64\n",
      "Male      0.547135\n",
      "Female    0.452865\n",
      "Name: gender, dtype: float64\n",
      "37    0.04785\n",
      "35    0.04741\n",
      "38    0.04664\n",
      "34    0.04532\n",
      "33    0.04433\n",
      "       ...   \n",
      "88    0.00011\n",
      "92    0.00011\n",
      "82    0.00011\n",
      "85    0.00011\n",
      "83    0.00011\n",
      "Name: age, Length: 70, dtype: float64\n",
      "1.0     0.104719\n",
      "2.0     0.104499\n",
      "8.0     0.102629\n",
      "3.0     0.102079\n",
      "5.0     0.101969\n",
      "7.0     0.101749\n",
      "4.0     0.097349\n",
      "9.0     0.097019\n",
      "6.0     0.096909\n",
      "10.0    0.049060\n",
      "0.0     0.042020\n",
      "Name: tenure, dtype: float64\n",
      "0.00         0.361126\n",
      "105473.74    0.000220\n",
      "130170.82    0.000220\n",
      "104088.59    0.000110\n",
      "99836.47     0.000110\n",
      "               ...   \n",
      "166287.85    0.000110\n",
      "110929.96    0.000110\n",
      "131406.56    0.000110\n",
      "91611.12     0.000110\n",
      "104001.38    0.000110\n",
      "Name: balance, Length: 5807, dtype: float64\n",
      "1    0.507865\n",
      "2    0.460235\n",
      "3    0.025740\n",
      "4    0.006160\n",
      "Name: num_of_products, dtype: float64\n",
      "1    0.704983\n",
      "0    0.295017\n",
      "Name: has_cr_card, dtype: float64\n",
      "1    0.515565\n",
      "0    0.484435\n",
      "Name: is_active_member, dtype: float64\n",
      "24924.92     0.00022\n",
      "109145.20    0.00011\n",
      "193746.55    0.00011\n",
      "96.27        0.00011\n",
      "190958.48    0.00011\n",
      "              ...   \n",
      "166324.79    0.00011\n",
      "147090.90    0.00011\n",
      "5698.97      0.00011\n",
      "190663.89    0.00011\n",
      "92320.37     0.00011\n",
      "Name: estimated_salary, Length: 9090, dtype: float64\n",
      "0    0.796062\n",
      "1    0.203938\n",
      "Name: exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Establecemos nuestro dataset sin valores ausentes\n",
    "data_no_nan = data.dropna(subset=['tenure'])\n",
    "\n",
    "# Construimos un bucle for que iterará por cada variable y devolverá sus valores relativos\n",
    "for col in data_no_nan:\n",
    "    print(data_no_nan[col].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se observan diferencias significativas entre nuestro dataset con valores ausentes y sin valores ausentes, por lo que se puede establecer que no existe un patrón subyacente o una variable que influya directamente sobre las cuentas a plazos fijos de clientes. Podría ser posible que algunos clientes simplemente no hacen uso de depósitos a plazos fijos dentro de esta institución bancaria. Considerando esto, vamos a utilizar una regresión lineal que prediga los valores de `tenure` y rellenaremos los valores NaN con estas predicciones. No se imputará los valores ausentes con la media o mediana, ya que afectará a la distribución de los datos y afectará la calidad del modelo. \n",
    "\n",
    "Empezamos codificando las características categóricas (`geography`, `gender`), que nos servirá para rellenar valores ausentes y para la posterior construcción de nuestro modelo predictivo. Para esto utilizaremos la codificación One-Hot(OHE) que transforma las características categóricas en numéricas, agregando columnas separadas para cada valor de la función, y asignando valores de 0 y 1. Utilizaremos la función get_dummies de pandas y pasaremos como argumentos el nombre de nuestro dataset y estableceremos drop_firt=True que eliminará a la primera columna para no confundir al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_of_products</th>\n",
       "      <th>has_cr_card</th>\n",
       "      <th>is_active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>exited</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_score  age  tenure    balance  num_of_products  has_cr_card  \\\n",
       "0           619   42     2.0       0.00                1            1   \n",
       "1           608   41     1.0   83807.86                1            0   \n",
       "2           502   42     8.0  159660.80                3            1   \n",
       "3           699   39     1.0       0.00                2            0   \n",
       "4           850   43     2.0  125510.82                1            1   \n",
       "\n",
       "   is_active_member  estimated_salary  exited  geography_Germany  \\\n",
       "0                 1         101348.88       1                  0   \n",
       "1                 1         112542.58       0                  0   \n",
       "2                 0         113931.57       1                  0   \n",
       "3                 0          93826.63       0                  0   \n",
       "4                 1          79084.10       0                  0   \n",
       "\n",
       "   geography_Spain  gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ohe = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "data_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con la construcción de nuestro modelo de imputación de ausentes, será necesario trabajar con dos datasets, uno que contenga solo valores ausentes `nan_data_ohe` y otro que no contenga valores ausentes `non_nan_data_ohe`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_data_ohe = data_ohe[data_ohe['tenure'].isna()]\n",
    "non_nan_data_ohe = data_ohe[~data_ohe['tenure'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecidos nuestro dos datasets, continuamos con la construcción de nuestro modelo de regresión lineal, guardamos nuestro algoritmo de aprendizaje en la variable `lr_nan` y luego entrenamos el modelo en base a nuestro dataset sin valores ausentes, utilizamos como objetivo del modelo a la variable `tenure` y las variables restantes serán las características. Posteriormente, rellenamos los valores ausentes con la función fillna, que utilizará los valores predecidos en base a nuestro dataset con solo valores NaN `nan_data_ohe`. Finalmente, transformaremos el tipo de dato a entero y comprobaremos los cambios llamando al método info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   credit_score       10000 non-null  int64  \n",
      " 1   age                10000 non-null  int64  \n",
      " 2   tenure             10000 non-null  int64  \n",
      " 3   balance            10000 non-null  float64\n",
      " 4   num_of_products    10000 non-null  int64  \n",
      " 5   has_cr_card        10000 non-null  int64  \n",
      " 6   is_active_member   10000 non-null  int64  \n",
      " 7   estimated_salary   10000 non-null  float64\n",
      " 8   exited             10000 non-null  int64  \n",
      " 9   geography_Germany  10000 non-null  uint8  \n",
      " 10  geography_Spain    10000 non-null  uint8  \n",
      " 11  gender_Male        10000 non-null  uint8  \n",
      "dtypes: float64(2), int64(7), uint8(3)\n",
      "memory usage: 732.5 KB\n"
     ]
    }
   ],
   "source": [
    "# Construcción de nuestro modelo de regresión lineal en base a nuestro dataset codificado sin valores ausentes\n",
    "lr_nan = LinearRegression()\n",
    "lr_nan.fit(non_nan_data_ohe.drop(columns='tenure'), non_nan_data_ohe['tenure'])\n",
    "\n",
    "# Reemplazo de valores ausentes con las predicciones realizadas por nuestro modelo\n",
    "data_ohe['tenure'].fillna(pd.Series\n",
    "                          (lr_nan.predict(nan_data_ohe.drop(columns='tenure')), \n",
    "                           index=nan_data_ohe.index),\n",
    "                          inplace=True)\n",
    "\n",
    "# Transformación del tipo de dato a entero \n",
    "data_ohe['tenure'] = data_ohe['tenure'].astype('int')\n",
    "\n",
    "# Comprobación de cambios\n",
    "data_ohe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "1. Se corrigieron los nombres de columnas que se encontraban en mayúsculas y se eliminaron las columnas `row_number`, `customer_id` y `surname` que no serán necesarias para la construcción de nuestro modelo predictivo. \n",
    "\n",
    "2. Para la imputación de valores ausentes en la columna `tenure`, se creó un modelo de regresión lineal que predijo el período de duración de un depósito de plazo fijo en función de las once características de nuestro dataset. Previamente se codificaron las características categóricas para el correcto funcionamiento del modelo. \n",
    "\n",
    "3. Nuestro dataset final `data_ohe` cuenta con 12 columnas y 10000 filas, nuestro objetivo es la varible `exited` y las 11 variables restantes serán utilizadas como características para entrenar nuestro modelos predictivos.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estandarización y segmentación de datos fuente\n",
    "\n",
    "Para este proyecto desarrollaremos un modelo predictivo de aprendizaje supervisado, ya que tratamos de reproducir un valor conocido de un conjunto de datos. El tipo de tarea con la que se trabajará es una tarea de clasificación binaria con un objetivo categórico que presenta dos posibles respuestas abandonó el banco-1 o no lo abandonó-0. \n",
    "\n",
    "Las características categóricas ya fueron previamente codificadas a través de la técnica de One-Hot Encoding, así que a continuación procederemos con la estandarización de características numéricas y segmentación de datos. \n",
    "\n",
    "### Estandarización de características numéricas\n",
    "\n",
    "Empezamos con la estandarización de características numéricas, esto se realiza para evitar que el algoritmo determine que una característica es más importante que la otra, al escalar los valores numéricos todas las características son igualmente importantes durante la ejecución del algoritmo. Para esto utilizaremos StandardScaler de la librería Scikit-Learn que ayuda a obtener una distribución estandarizada, con una media de cero y una desviación estándar de uno. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_of_products</th>\n",
       "      <th>has_cr_card</th>\n",
       "      <th>is_active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>exited</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.326221</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>-1.066566</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.440036</td>\n",
       "      <td>0.198164</td>\n",
       "      <td>-1.427869</td>\n",
       "      <td>0.117350</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.536794</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>1.101252</td>\n",
       "      <td>1.333053</td>\n",
       "      <td>2.527057</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240687</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.501521</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>-1.427869</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.108918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.063884</td>\n",
       "      <td>0.388871</td>\n",
       "      <td>-1.066566</td>\n",
       "      <td>0.785728</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.365276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_score       age    tenure   balance  num_of_products  has_cr_card  \\\n",
       "0     -0.326221  0.293517 -1.066566 -1.225848        -0.911583            1   \n",
       "1     -0.440036  0.198164 -1.427869  0.117350        -0.911583            0   \n",
       "2     -1.536794  0.293517  1.101252  1.333053         2.527057            1   \n",
       "3      0.501521  0.007457 -1.427869 -1.225848         0.807737            0   \n",
       "4      2.063884  0.388871 -1.066566  0.785728        -0.911583            1   \n",
       "\n",
       "   is_active_member  estimated_salary  exited  geography_Germany  \\\n",
       "0                 1          0.021886       1                  0   \n",
       "1                 1          0.216534       0                  0   \n",
       "2                 0          0.240687       1                  0   \n",
       "3                 0         -0.108918       0                  0   \n",
       "4                 1         -0.365276       0                  0   \n",
       "\n",
       "   geography_Spain  gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardamos las características numéricas en la variable numeric\n",
    "numeric = ['credit_score', 'age', 'tenure', 'balance', 'num_of_products', 'estimated_salary']\n",
    "\n",
    "# Llamamos a StandardScaler y lo guardamos en la variable scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustamos y transformamos a nuestros datos numéricos\n",
    "scaler.fit(data_ohe[numeric])\n",
    "data_ohe[numeric] = scaler.transform(data_ohe[numeric])\n",
    "\n",
    "# Comprobamos los cambios\n",
    "data_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentación de datos\n",
    "\n",
    "Una vez codificados y estandarizados nuestras características categóricas y numéricas, vamos a proceder con la segmentación. En este caso, será necesario dividir nuestros datos en tres datasets: dataset de entrenamiento, dataset de validación y dataset prueba. Se realizará esta división ya que no contamos con un dataset de prueba y un dataset de validación mostrará como se comporta el modelo y si existe un sobreajuste. \n",
    "\n",
    "Al dividir un dataset fuente en tres partes la proporción ideal es de 3:1:1, es decir el 60% de datos se asignarán al conjunto de entrenamiento, 20% al conjunto de validación y 20% al conjunto de prueba. Para realizar la división utilizaremos la función `train_test_split` de la librería Skicit-Learn. \n",
    "\n",
    "Empezaremos dividiendo nuestro dataset fuente `df` en el conjunto de datos para el entrenamiento `data_train` con el 60% de datos, y `data_40` que contendrá el 40% de los datos, para esto estableceremos los parámetros `test_size` en 0.40 y `random_state` en 12345. Posteriormente, vamos a dividir `data_40` en nuestros conjuntos de validación `data_valid` y de prueba `data_test`. Cada conjunto contiene el 20% de los datos, por lo que estableceremos `test_size` en 0.50, para obtener dos datasets que contengas el 50% del dataset `df_40` que a su vez correspondría con el 20% del dataset fuente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_40 = train_test_split(data_ohe, test_size=0.40, random_state=12345)\n",
    "\n",
    "data_valid, data_test = train_test_split(data_40, test_size=0.50, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que nuestros conjunto de datos de entrenamiento `data_train`, validación `data_valid` y prueba `data_test` se hayan dividido correctamente llamando al atributo shape en cada dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas y columnas conjunto de entrenamiento: (6000, 12)\n",
      "\n",
      "Número de filas y columnas conjunto de validación: (2000, 12)\n",
      "\n",
      "Número de filas y columnas conjunto de prueba: (2000, 12)\n"
     ]
    }
   ],
   "source": [
    "print('Número de filas y columnas conjunto de entrenamiento:', data_train.shape)\n",
    "print()\n",
    "print('Número de filas y columnas conjunto de validación:', data_valid.shape)\n",
    "print()\n",
    "print('Número de filas y columnas conjunto de prueba:', data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se verifica entonces que el dataset de entrenamiento contiene el 60% de datos(6000 observaciones), y los dataset de validación y prueba el 20% de datos(2000 observaciones cada uno). \n",
    "\n",
    "Una vez establecidos nuestros tres conjuntos de datos, vamos a establecer las características y objetivos de cada dataset. Para las características vamos a utilizar la función drop que eliminará la columna `exited`, y nos quedaremos únicamente con las columnas restantes, guardaremos estos resultados en las variables `features_train`, `features_valid` y `features_test`. Para el objetivo de cada dataset simplemente llamaremos a la columna `exited` y se guardarán estos valores en las variables `target_train`, `target_valid` y `target_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecemos las características y objetivo del conjunto de datos para el entrenamiento\n",
    "features_train = data_train.drop('exited', axis=1)\n",
    "target_train = data_train['exited']\n",
    "\n",
    "# Establecemos las características y objetivo del conjunto de datos para la validación\n",
    "features_valid = data_valid.drop('exited', axis=1)\n",
    "target_valid = data_valid['exited']\n",
    "\n",
    "# Establecemos las características y objetivo del conjunto de datos para la prueba\n",
    "features_test = data_test.drop('exited', axis=1)\n",
    "target_test = data_test['exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que los nuevos datasets solo guarden las once características llamando al método info en cada conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6000 entries, 7479 to 4578\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   credit_score       6000 non-null   float64\n",
      " 1   age                6000 non-null   float64\n",
      " 2   tenure             6000 non-null   float64\n",
      " 3   balance            6000 non-null   float64\n",
      " 4   num_of_products    6000 non-null   float64\n",
      " 5   has_cr_card        6000 non-null   int64  \n",
      " 6   is_active_member   6000 non-null   int64  \n",
      " 7   estimated_salary   6000 non-null   float64\n",
      " 8   geography_Germany  6000 non-null   uint8  \n",
      " 9   geography_Spain    6000 non-null   uint8  \n",
      " 10  gender_Male        6000 non-null   uint8  \n",
      "dtypes: float64(6), int64(2), uint8(3)\n",
      "memory usage: 439.5 KB\n"
     ]
    }
   ],
   "source": [
    "features_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2000 entries, 8532 to 6895\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   credit_score       2000 non-null   float64\n",
      " 1   age                2000 non-null   float64\n",
      " 2   tenure             2000 non-null   float64\n",
      " 3   balance            2000 non-null   float64\n",
      " 4   num_of_products    2000 non-null   float64\n",
      " 5   has_cr_card        2000 non-null   int64  \n",
      " 6   is_active_member   2000 non-null   int64  \n",
      " 7   estimated_salary   2000 non-null   float64\n",
      " 8   geography_Germany  2000 non-null   uint8  \n",
      " 9   geography_Spain    2000 non-null   uint8  \n",
      " 10  gender_Male        2000 non-null   uint8  \n",
      "dtypes: float64(6), int64(2), uint8(3)\n",
      "memory usage: 146.5 KB\n"
     ]
    }
   ],
   "source": [
    "features_valid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2000 entries, 7041 to 3366\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   credit_score       2000 non-null   float64\n",
      " 1   age                2000 non-null   float64\n",
      " 2   tenure             2000 non-null   float64\n",
      " 3   balance            2000 non-null   float64\n",
      " 4   num_of_products    2000 non-null   float64\n",
      " 5   has_cr_card        2000 non-null   int64  \n",
      " 6   is_active_member   2000 non-null   int64  \n",
      " 7   estimated_salary   2000 non-null   float64\n",
      " 8   geography_Germany  2000 non-null   uint8  \n",
      " 9   geography_Spain    2000 non-null   uint8  \n",
      " 10  gender_Male        2000 non-null   uint8  \n",
      "dtypes: float64(6), int64(2), uint8(3)\n",
      "memory usage: 146.5 KB\n"
     ]
    }
   ],
   "source": [
    "features_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se comprueba que las variables features solo presenta las 11 características necesarias para la construcción de nuestros modelos en los tres conjuntos de datos. Así que ahora podemos proceder con la construcción de modelos predictivos. \n",
    "\n",
    "## Desequilibrio de clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a examinar el equilibrio de clases en nuestro objetivo `exited` para esto llamaremos a value_counts() en nuestra variable target_train del conjunto de datos de entrenamiento, y también trazaremos gráficos de barras para visualizar mejor los resultados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.800667\n",
      "1    0.199333\n",
      "Name: exited, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(target_train.value_counts(normalize=True))\n",
    "target_train.value_counts(normalize=True).plot(kind='bar', rot=0)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Exited')\n",
    "plt.title('Desequilibrio de clases')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las clases se encuentran desequilibradas cuando su proporción está lejos de 1:1, el equilibrio de clases se observa cuando el número es aproximadamente igual. En nuestro datos podemos observar un marcado desbalance de clases, con un 20% de clientes que han abandonado la entidad bancaria y un 80% que todavía permanecen dentro de la institución. Con una relación de 4:1, podemos establecer una diferencia significativa, así que se confirma un desequilibrio de clases para nuestros datos. Considerando esto, no se podrá utilizar métricas como la exactitud, ya que son más sensibles a un desbalance en las clases, siendo la mejor opción trabajar con la métrica F1. \n",
    "\n",
    "Confirmado el desequilibrio de clases, vamos a construir modelos sin tomar en consideración el desbalance y luego construiremos modelos tomando en cuenta el desbalance a través del sobremuestreo, submuestreo y el ajuste de peso de clase. \n",
    "\n",
    "## Modelos sin desequilibrio de clases\n",
    "\n",
    "Empecemos construyendo modelos sin considerar el desequilibrio de clases, esto nos permitirá ver cómo se comportan los diferentes modelos y métricas ante este desbalance. Utilizaremos tres algoritmos de aprendizaje para la construcción de estos modelos: Árbol de Decisión, Bosque Aleatorio y Regresión Logística. \n",
    "\n",
    "Para evaluar la calidad del modelo nos enfocaremos en dos métricas:\n",
    "\n",
    "- **Valor F1:** es una métrica que evalúa un modelo con puntajes que van de 0 a 1, dónde 1 es el mejor puntaje y 0 es el peor puntaje y determina que la predicción ha fallado. Es una de las mejore métricas para evaluar datasets con desequilibrio de clases, como nuestros datos. El valor F1 representa la media armónica y evalua tanto la precisión como la sensibilidad o Recall. \n",
    "- **AUC-ROC:** Área Bajo la Curva de la Característica Operativa del Receptor, es una métrica que evalúa modelos de predicción con valores de 0.5 a 1, dónde 1 es el mejor puntaje que se puede alcanzar y 0.5 el modelo es igual a un modelo aleatorio. Nos permite establecer cuánto difiere nuestro modelo de un modelo aleatorio. Este modelo se construye en base a la curva ROC que compara la tasa de verdaderos positivos y la tasa de falsos positivos.\n",
    "\n",
    "### Árbol de Decisión\n",
    "\n",
    "El primer algoritmo de aprendizaje supervisado que utilizaremos es un árbol de decisión, este divide los datos en dos o más conjuntos homogéneos y utiliza reglas if-then o condiciones para separar los datos según las dos categorías que se busca predecir. Para trabajar con un árbol de decisión clasificatorio vamos a llamar a la función DecissionTreeClassifier del módulo tree en la librería Scikit-Learn, lo que ya hemos realizado en la sección de inicialización. \n",
    "\n",
    "Guardaremos a nuestro modelo en la variable `tree_model`, dentro de la cual llamaremos a la función DecissionTreeClassifier y estableceremos el hiperparamétro random_state=12345 para poder duplicar modelos existosos utilizando el mismo conjunto de números pseudoaleatorios. Para establecer la profundidad máxima o el número máximo de condiciones más apropiada para nuestro modelo, construiremos un bucle for que iterará por diferentes profundidades dentro del rango de 1 a 10. \n",
    "\n",
    "Posteriormente, vamos a entrenar nuestro modelo para esto pasaremos las características y el objetivo de nuestro conjunto de entrenamiento como argumento de la función fit. Luego crearemos la variable `predicted_valid` que predecirá los valores 0 o 1 con los datos del conjunto de validación. En base a estos valores calcularemos `f1_score`. También calcularemos las probabilidades con el valor de `auc_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol de Decisión con desbalance de clases (max_depth = 9)| F1_Score = 0.5710187, AUC_ROC = 0.7825878\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_depth = 0\n",
    "auc_score = 0\n",
    "\n",
    "for depth in range(1, 11):\n",
    "    tree_model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    tree_model.fit(features_train, target_train)\n",
    "    \n",
    "    predicted_valid = tree_model.predict(features_valid)\n",
    "    probabilites_valid = tree_model.predict_proba(features_valid)\n",
    "    probabilites_one_valid = probabilites_valid[:, 1]\n",
    "    \n",
    "    score = f1_score(target_valid, predicted_valid) \n",
    "    auc_roc = roc_auc_score(target_valid, probabilites_one_valid)\n",
    "    \n",
    "    if score > best_score:\n",
    "            \n",
    "        best_score = score\n",
    "        best_depth = depth\n",
    "        auc_score = auc_roc\n",
    "    \n",
    "print(\n",
    "        'Árbol de Decisión con desbalance de clases (max_depth = {})| F1_Score = {:.7f}, AUC_ROC = {:.7f}'.format(\n",
    "                best_depth, best_score, auc_score\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el modelo de árbol de decisión con desequilibrio de clases el valor F1 más alto registrado corresponde a una profundidad máxima de 9, con un F1 de 0.5710 y un AUC-ROC de 0.7825. El valor F1 es inferior al umbral mínimo de 0.59 que busca este proyecto. \n",
    "\n",
    "### Bosque Aleatorio\n",
    "\n",
    "Nuestro segundo modelo lo vamos a construir a partir del algoritmo de aprendizaje conocido como Bosque Aleatorio. Estos se basan en árboles de decisión, pero no entrena un sólo árbol sino un bosque o una gran cantidad de árboles independientes y toman decisiones mediante el voto, es decir suman los votos de diferentes formaciones aleatorias de los árboles de decisión para determinar la clase final a la que pertenece un cliente. \n",
    "\n",
    "Para determinar el modelo de Bosque Aleatorio con mayor exactitud vamos a llamar a la función RandomForestClassifier del módulo ensemble de la librería Scikit-Learn, y guardaremos nuestro modelo en la variable `forest_model`. Dentro de la función pasaremos el hiperpárametro random_state=12345 para poder replicar nuestro modelo utilizando los mismos números pseudoaleatorios. En el caso de los hiperparámetros n-estimators(número de árboles en el bosque) y max_depth(profundidad máxima) vamos a generar un doble bucle for que iterará por un rango de profundidades de 1 a 10 y un rango de árboles de 10 a 50, en intervalos de 10, estableciendo así los valores ideales para un mejor modelo. \n",
    "\n",
    "Entrenaremos nuestro modelo `forest_model` con nuestro conjunto de datos para el entrenamiento `features_train` y `target_train`, y posteriormente evaluaremos la calidad de nuestro modelo aplicando la función f1_score y roc_auc_score al objetivo del conjunto de validación. Para poder determinar el número de árboles y profundidad máxima que generó el modelo con mayor exactitud vamos a establecer tres contadores `best_score`, `best_est` y `best_depth` que si registran el valor de exactitud más alto, guardarán los valores de max_depth y n_estimators que generaron dicha exactitud en los contadores previamente mencionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bosque Aleatorio con desbalance de clases (n_estimators = 20, max_depth = 9) | F1 = 0.574924, AUC-ROC = 0.848913\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "auc_score = 0\n",
    "\n",
    "for est in range(10,51,10):\n",
    "    \n",
    "    for depth in range(1,11):\n",
    "        \n",
    "        forest_model= RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        \n",
    "        forest_model.fit(features_train, target_train)\n",
    "        predicted_valid = forest_model.predict(features_valid)\n",
    "        \n",
    "        probabilites_valid = forest_model.predict_proba(features_valid)\n",
    "        probabilites_one_valid = probabilites_valid[:, 1]\n",
    "        \n",
    "        score = f1_score(target_valid, predicted_valid)\n",
    "        auc_roc = roc_auc_score(target_valid, probabilites_one_valid)\n",
    "        \n",
    "        if score > best_score:\n",
    "            \n",
    "            best_score = score\n",
    "            best_est = est\n",
    "            best_depth = depth\n",
    "            auc_score = auc_roc\n",
    "            \n",
    "print(\n",
    "    \n",
    "    \"Bosque Aleatorio con desbalance de clases (n_estimators = {}, max_depth = {}) | F1 = {:.6f}, AUC-ROC = {:.6f}\".format(\n",
    "        best_est, best_depth, best_score, auc_score)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para nuestro modelo de Bosque Aleatorio se registró el valor F1 más alto 0.5749 para 20 estimadores y un profundidad máxima de 9, a su vez el valor AUC-ROC registrado fue de 0.8489. Al igual que el modelo anterior obtenemos un valor F1 que no llega al umbral de este proyecto, sin embargo el valor AUC-ROC obtenido es de 0.8489 lo que indica que si bien el modelo no presenta una buena precisión y sensibilidad, es bueno prediciendo valores verdaderos positivos. \n",
    "\n",
    "\n",
    "### Regresión Logística\n",
    "\n",
    "El tercer algoritmo de aprendizaje que utilizaremos para entrenar a nuestro modelo será el de Regresión Logística. Este algoritmo coloca nuestros datos en forma de una curva sigmoide y establece la probabilidad de que las diferentes características correspondan a la clase 1 o 0. El modelo calcula la proximidad de clase para cada observación en los datos de entrenamiento y les asigna leyendas, si la probabilidad es más cercana a cero se clasificará como NoExited-0 y si la probabilidad es más cercana a 1 entonces se clasificará como Exited-1.\n",
    "\n",
    "Llamaremos a nuestro modelo `regression_model` y llamaremos a la función LogisticRegressión del módulo linear_model de la librería Scikit-learn, a esta función pasaremos los hiperparámetros para el posterior entrenamiento del modelo. Estableceremos los hiperparámetros random_state=12345 que volverá estática la pseudoaleatoriedad y solver=liblinear que se utiliza para el ajuste de curva del algoritmo en datasets pequeños. \n",
    "\n",
    "Posteriormente, calcularemos el puntaje F1 a partir de los valores de objetivo y predicciones realizadas a partir del conjunto de validación. Así mismo, se calculará AUC-ROC a partir de la predicción de probabilidades de nuestros datos de validación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresión Logística con desbalance de clases | F1 = 0.333333, AUC-ROC = 0.758895\n"
     ]
    }
   ],
   "source": [
    "regression_model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "\n",
    "regression_model.fit(features_train, target_train)\n",
    "\n",
    "predicted_valid = regression_model.predict(features_valid)\n",
    "\n",
    "probabilites_valid = regression_model.predict_proba(features_valid)\n",
    "probabilites_one_valid = probabilites_valid[:, 1]\n",
    "\n",
    "score = f1_score(target_valid, predicted_valid)\n",
    "auc_score = roc_auc_score(target_valid, probabilites_one_valid)\n",
    "\n",
    "print(\n",
    "    \n",
    "    \"Regresión Logística con desbalance de clases | F1 = {:.6f}, AUC-ROC = {:.6f}\".format(\n",
    "        score, auc_score)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el modelo de regresión logística el valor F1 alcanzado es de 0.3333 y AUC-ROC de 0.7588, lo que representa el valor más bajo entre los tres modelos estudiados, encontrándose significativamente por debajo del umbral de 0.59 que busca este estudio. Sin embargo, el valor de AUC-ROC fue inferior a el modelo de árbol de decisión. \n",
    "\n",
    "### Conclusiones\n",
    "\n",
    "Al construir modelos sin considerar el desbalance de clases, se estableció que el modelo de Bosque Aleatorio es el que alcanzó el puntaje F1 más alto, sin embargo no alcanzó el umbral que busca este estudio de 0.59. En el caso del valor de AUC-ROC el valor más alto fue para el bosque aleatorio y el más bajo para el modelo de regresión logística. El modelo que registró el valor F1 más bajo fue el de Regresión Logística. \n",
    "\n",
    "Cuando no tomamos en consideración el desbalance de clases en nuestro conjunto de datos, el valor F1 es inferior al deseado. Esto debido a que F1 se calcula a partir de la media armónica entre la precisión y la sensibilidad, por lo que solo toma en cuenta a verdaderos positivos, falsos positivos y falsos negativos. Al construir los modelos ignorando que la clase negativa es la que se encuentra en mayor proporción, nuestros modelos no están entrenados para predecir correctamente la clase con un mayor peso, en este caso los verdaderos negativos, haciendo que el valor F1 no alcance el umbral deseado. \n",
    "\n",
    "Por otro lado, en el caso del valor AUC-ROC se registraron valores por encima de 0.70 para los tres modelos estudiados. Si consideramos que esta métrica se construye en base a umbrales de la tasa de verdaderos positivos y la tasa de falsos positivos; al no tomar en cuenta el desbalance de clases, la tasa de falsos positivos incrementará debido a que los negativos se encuentran en mayor propoción y están siendo predecidos como positivos, haciendo que los valores AUC-ROC incrementen sin mucho esfuerzo. Por lo que se puede concluir que la métrica AUC-ROC es mucho más susceptible al desquilibrio de clases. \n",
    "\n",
    "\n",
    "## Modelos con desequilibrio de clases\n",
    "\n",
    "Ahora construiremos modelos tomando en consideración el desequilibrio de clases, probaremos con tres técnicas para corregir este desbalance: \n",
    "- Sobremuestreo\n",
    "- Submuestreo\n",
    "- Ajuste de peso de clase. \n",
    "\n",
    "Aplicaremos estas técnicas para construir diferentes modelos de aprendizaje supervisado, y utilizaremos tres algoritmos de aprendizaje: árbol de decisión, bosque aleatorio y regresión logística. Escogeremos el modelo con los hiperparámetros específicos que alcancen un valor F1 superior a 0.59.  \n",
    "\n",
    "### Sobremuestreo\n",
    "\n",
    "El sobremuestreo busca que las observaciones de una clase rara se vuelvan menos raras. En nuestro caso, duplicaremos las observaciones de la clase 1 para que se vuelva más frecuente. Para realizar esto construiremos la función `upsample` que dividirá el conjunto de datos de entrenamiento en observaciones positivas y negativas. Duplicará las observaciones positivas varias veces, y creará una nueva muestra de entrenamiento `features_upsampled` y `target_upsampled`. Finalmente se mezclará la nueva muestra  a través de la función shuffle de Scikit-learn. Contará con los siguientes argumentos:\n",
    "\n",
    "- `features:` características del conjunto de entrenamiento\n",
    "- `target:` objetivo del conjunto de entrenamiento\n",
    "- `repeat:` número de repeticiones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    \n",
    "# Dividimos en observaciones positivas y negativas\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "# Duplicamos las observaciones raras varias veces \n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    \n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "# Barajamos los datos para el entrenamiento\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, \n",
    "                                                   target_upsampled, \n",
    "                                                   random_state=12345)\n",
    "    return features_upsampled, target_upsampled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez construida la función `upsample` la vamos a aplicar a nuestro conjunto de entrenamiento y estableceremos el número de repeticiones en 4. Posteriormente comprobaremos el tamaño de nuestra nueva muestra a través del atributo shape y comprobaremos la distribución de valores entre ambas clases con value_counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño características sobremuestreo: (9588, 11)\n",
      "Tamaño objetivo sobremuestreo: (9588,)\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos la función a nuestro conjunto de entrenamiento \n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 4)\n",
    "\n",
    "# Comprobamos el tamaño de muestra\n",
    "print('Tamaño características sobremuestreo:', features_upsampled.shape)\n",
    "print('Tamaño objetivo sobremuestreo:', target_upsampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4804\n",
       "1    4784\n",
       "Name: exited, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_upsampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecido nuestra nueva muestra de entrenamiento, vamos a entrenar diferentes modelos para observar cómo influye esta técnica de correción de desequilibrio de clases. Utilizaremos la misma metodología para la construcción de modelos que se aplicó en los modelos sin desequilibrio de clases. \n",
    "\n",
    "**ÁRBOL DE DECISIÓN SOBREMUESTREO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol de Decisión con Sobremuestreo (max_depth = 5)| F1_Score = 0.5963791, AUC_ROC = 0.8310244\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_depth = 0\n",
    "auc_score = 0\n",
    "\n",
    "for depth in range(1, 12):\n",
    "    dt_umsampled = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    dt_umsampled.fit(features_upsampled, target_upsampled)\n",
    "    \n",
    "    predicted_valid = dt_umsampled.predict(features_valid)\n",
    "    \n",
    "    probabilites_valid = dt_umsampled.predict_proba(features_valid)\n",
    "    probabilites_one_valid = probabilites_valid[:, 1]\n",
    "    \n",
    "    score = f1_score(target_valid, predicted_valid) \n",
    "    auc_roc = roc_auc_score(target_valid, probabilites_one_valid)\n",
    "    \n",
    "    if score > best_score:\n",
    "            \n",
    "        best_score = score\n",
    "        best_depth = depth\n",
    "        auc_score = auc_roc\n",
    "    \n",
    "print(\n",
    "        'Árbol de Decisión con Sobremuestreo (max_depth = {})| F1_Score = {:.7f}, AUC_ROC = {:.7f}'.format(\n",
    "                best_depth, best_score, auc_score\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BOSQUE ALEATORIO SOBREMUESTREO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bosque Aleatorio con Sobremuestreo (n_estimators = 40, max_depth = 9) | F1 = 0.624464, AUC-ROC = 0.854218\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "auc_score = 0\n",
    "\n",
    "for est in range(10,51,10):\n",
    "    \n",
    "    for depth in range(1,11):\n",
    "        \n",
    "        rf_upsampled= RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        \n",
    "        rf_upsampled.fit(features_upsampled, target_upsampled)\n",
    "        predicted_valid = rf_upsampled.predict(features_valid)\n",
    "        probabilites_valid = rf_upsampled.predict_proba(features_valid)\n",
    "        probabilites_one_valid = probabilites_valid[:, 1]\n",
    "        \n",
    "        score = f1_score(target_valid, predicted_valid)\n",
    "        auc_roc = roc_auc_score(target_valid, probabilites_one_valid)\n",
    "        \n",
    "        if score > best_score:\n",
    "            \n",
    "            best_score = score\n",
    "            best_est = est\n",
    "            best_depth = depth\n",
    "            auc_score = auc_roc\n",
    "\n",
    "print(\n",
    "    \n",
    "    \"Bosque Aleatorio con Sobremuestreo (n_estimators = {}, max_depth = {}) | F1 = {:.6f}, AUC-ROC = {:.6f}\".format(\n",
    "        best_est, best_depth, best_score, auc_score)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REGRESIÓN LOGÍSTICA SOBREMUESTREO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresión Logística con Sobremuestreo | F1 = 0.491409, AUC-ROC = 0.763872\n"
     ]
    }
   ],
   "source": [
    "rl_upsampled = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "\n",
    "rl_upsampled.fit(features_upsampled, target_upsampled)\n",
    "\n",
    "predicted_valid = rl_upsampled.predict(features_valid)\n",
    "\n",
    "probabilites_valid = rl_upsampled.predict_proba(features_valid)\n",
    "probabilites_one_valid = probabilites_valid[:, 1]\n",
    "\n",
    "score = f1_score(target_valid, predicted_valid)\n",
    "auc_score = roc_auc_score(target_valid, probabilites_one_valid)\n",
    "\n",
    "print(\n",
    "    \n",
    "    \"Regresión Logística con Sobremuestreo | F1 = {:.6f}, AUC-ROC = {:.6f}\".format(\n",
    "        score, auc_score)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor modelo para el sobremuestreo fue el Bosque Aleatorio con 40 estimadores y 9 de profundidad máxima, alcanzando un valor F1 de 0.6244 y un AUC-ROC de 0.8542, encontrándose por encima del umbral establecido. En segundo lugar, se encuentra el modelo de Árbol de decisión que alcanzó un puntaje F1 de 0.5963 y un AUC-ROC de 0.8310, justo por encima del valor 0.59. En el caso del modelo de regresión logística, se obtuvieron valores por debajo del umbral incluso aplicando la técnica de sobremuestreo. Hay que considerar que el tiempo de ejecución del modelo de Bosque Aleatorio es superior al Árbol de Decisión, por lo que si queremos ahorrar tiempo se podría considerar este modelo predictivo. \n",
    "\n",
    "### Submuestreo\n",
    "\n",
    "Ahora vamos a aplicar la técnica de submuestreo, que busca que las observaciones de una clase frecuente sean menos frecuentes, en este caso vamos a eliminar al azar un parte de las observaciones negativas que son la clase con mayor proporción en nuestro conjunto de datos. Para lograr esto, procederemos a construir la función `downsample` que dividirá el conjunto de datos para el entrenamiento en observaciones positivas y negativas. Luego, soltará al azar una parte de las observaciones negativas a través de la función sample que descarta de forma aleatoria algunos elementos de la tabla. A continuación, creará una nueva muestra de entrenamiento `features_downsampled` y `target_downsampled`, basada en los datos después de la pérdida de valores. Finalmente, mezclará los datos a través de la función shuffle. La función contará con los siguientes argumentos:\n",
    "\n",
    "- `features:` características del conjunto de entrenamiento\n",
    "- `target:` objetivo del conjunto de entrenamiento\n",
    "- `fraction:` argumento de la función sample que estable la fracción de elementos que se devolverá. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    \n",
    "# Dividimos el conjunto de entrenamiento en observaciones positivas y negativas\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "# Soltamos al azar las observaciones negativas con la función sample\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    \n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    \n",
    "# Mezclamos los datos a través de la función shuffle\n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled, \n",
    "                                                   target_downsampled, \n",
    "                                                   random_state=12345)\n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez definida nuestra función procedemos a establecer nuestras nuevas variables de entrenamiento, para esto pasamos como argumentos a nuestra función el conjunto de datos de entrenamiento y fraction igual a 0.25 (proporción de clases desbalanceadas 20/80=0.25).  Comprobamos el tamaño de nuestra nueva muestra llamando al atributo shape y a la función value_counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño características submuestreo: (2397, 11)\n",
      "Tamaño objetivo submuestreo: (2397,)\n"
     ]
    }
   ],
   "source": [
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.25)\n",
    "\n",
    "print('Tamaño características submuestreo:', features_downsampled.shape)\n",
    "print('Tamaño objetivo submuestreo:', target_downsampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.501043\n",
       "1    0.498957\n",
       "Name: exited, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CELDA DE REVISOR\n",
    "\n",
    "target_downsampled.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1201\n",
       "1    1196\n",
       "Name: exited, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_downsampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a aplicar la función a diferentes modelos de aprendizaje supervisado, hasta encontrar aquel modelo e hiperparámetros que generen el valor F1 por encima del umbral deseado. \n",
    "\n",
    "**ÁRBOL DE DECISIÓN SUBMUESTREO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol de Decisión con Submuestreo (max_depth = 5)| F1_Score = 0.5943205, AUC_ROC = 0.8241029\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_depth = 0\n",
    "auc_score = 0\n",
    "\n",
    "for depth in range(1, 12):\n",
    "    dt_downsampled = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    dt_downsampled.fit(features_downsampled, target_downsampled)\n",
    "    \n",
    "    predicted_valid = dt_downsampled.predict(features_valid)\n",
    "    probabilites_valid = dt_downsampled.predict_proba(features_valid)\n",
    "    probabilites_one_valid = probabilites_valid[:, 1]\n",
    "    \n",
    "    score = f1_score(target_valid, predicted_valid) \n",
    "    auc_roc = roc_auc_score(target_valid, probabilites_one_valid)\n",
    "    \n",
    "    if score > best_score:\n",
    "            \n",
    "        best_score = score\n",
    "        best_depth = depth\n",
    "        auc_score = auc_roc\n",
    "    \n",
    "print(\n",
    "        'Árbol de Decisión con Submuestreo (max_depth = {})| F1_Score = {:.7f}, AUC_ROC = {:.7f}'.format(\n",
    "                best_depth, best_score, auc_score\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BOSQUE ALEATORIO SUBMUESTREO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bosque Aleatorio con Submuestreo (n_estimators = 10, max_depth = 4) | F1 = 0.609218, AUC-ROC = 0.835469\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "auc_score = 0\n",
    "\n",
    "for est in range(10,51,10):\n",
    "    \n",
    "    for depth in range(1,11):\n",
    "        \n",
    "        rf_downsampled = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        \n",
    "        rf_downsampled.fit(features_downsampled, target_downsampled)\n",
    "        predicted_valid = rf_downsampled.predict(features_valid)\n",
    "        probabilites_valid = rf_downsampled.predict_proba(features_valid)\n",
    "        probabilites_one_valid = probabilites_valid[:, 1]\n",
    "        \n",
    "        score = f1_score(target_valid, predicted_valid)\n",
    "        auc_roc = roc_auc_score(target_valid, probabilites_one_valid)\n",
    "        \n",
    "        if score > best_score:\n",
    "            \n",
    "            best_score = score\n",
    "            best_est = est\n",
    "            best_depth = depth\n",
    "            auc_score = auc_roc\n",
    "\n",
    "print(\n",
    "    \n",
    "    \"Bosque Aleatorio con Submuestreo (n_estimators = {}, max_depth = {}) | F1 = {:.6f}, AUC-ROC = {:.6f}\".format(\n",
    "        best_est, best_depth, best_score, auc_score)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REGRESIÓN LOGÍSTICA SUBMUESTREO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresión Logística con Submuestreo | F1 = 0.489691, AUC-ROC = 0.762666\n"
     ]
    }
   ],
   "source": [
    "rl_downsampled = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "\n",
    "rl_downsampled.fit(features_downsampled, target_downsampled)\n",
    "\n",
    "predicted_valid = rl_downsampled.predict(features_valid)\n",
    "\n",
    "probabilites_valid = rl_downsampled.predict_proba(features_valid)\n",
    "probabilites_one_valid = probabilites_valid[:, 1]\n",
    "\n",
    "score = f1_score(target_valid, predicted_valid)\n",
    "auc_score = roc_auc_score(target_valid, probabilites_one_valid)\n",
    "\n",
    "print(\n",
    "    \n",
    "    \"Regresión Logística con Submuestreo | F1 = {:.6f}, AUC-ROC = {:.6f}\".format(\n",
    "        score, auc_score)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando la técnica de submuestreo para corregir el desbalance de clases, se obtuvieron dos modelos con un puntaje F1 superior al umbral de 0.59: Árbol de Decisión y Bosque Aleatorio. Para el modelo de árbol de decisión con submuestreo se obtuvo un F1 de 0.5943 a una profundidad máxima de cinco, mientras que para el modelo de bosque aleatorio con submuestreo se obtuvo un puntuaje F1 igual a 0.6092 con 10 estimadores y 4 de profundidad máxima. El AUC-ROC más alto fue para el modelo de bosque aleatorio. En el caso del modelo de regresión logística no alcanzó el umbral mínimo de 0.59, registrando un F1 de 0.4869."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste de peso de clase\n",
    "\n",
    "La última técnica para el desbalance de clases será el ajuste de peso de clase. Para esto utilizaremos el parámetro `class_weight` de los algoritmos de aprendizaje. Generalmente, este parámetro se encuentra en None lo que hace que ambas clases tengan el mismo peso, si cambiamos este parámetro a `balanced`, la clase negativa tendrá un mayor peso que la positiva. Para esto simplemente entrenaremos nuestros modelos añadiendo este hiperparámetro a los tres algoritmos de aprendizaje con los que hemos estado trabajando hasta el momento. \n",
    "\n",
    "**ÁRBOL DE DECISIÓN CON AJUSTE DE CLASE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol de Decisión con Ajuste de Clase (max_depth = 5)| F1_Score = 0.5963791, AUC_ROC = 0.8310244\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_depth = 0\n",
    "auc_score = 0\n",
    "\n",
    "for depth in range(1, 11):\n",
    "    dt_balanced = DecisionTreeClassifier(random_state=12345, max_depth=depth, class_weight='balanced')\n",
    "    dt_balanced.fit(features_train, target_train)\n",
    "    \n",
    "    predicted_valid = dt_balanced.predict(features_valid)\n",
    "    probabilites_valid = dt_balanced.predict_proba(features_valid)\n",
    "    probabilites_one_valid = probabilites_valid[:, 1]\n",
    "    \n",
    "    score = f1_score(target_valid, predicted_valid) \n",
    "    auc_roc = roc_auc_score(target_valid, probabilites_one_valid)\n",
    "        \n",
    "    if score > best_score:\n",
    "            \n",
    "        best_score = score\n",
    "        best_depth = depth\n",
    "        auc_score = auc_roc\n",
    "    \n",
    "print(\n",
    "        'Árbol de Decisión con Ajuste de Clase (max_depth = {})| F1_Score = {:.7f}, AUC_ROC = {:.7f}'.format(\n",
    "                best_depth, best_score, auc_score\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BOSQUE ALEATORIO CON AJUSTE DE CLASE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bosque Aleatorio con Ajuste de Clase (n_estimators = 40, max_depth = 10) | F1 = 0.627262, AUC-ROC = 0.846928\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "auc_score = 0\n",
    "\n",
    "for est in range(10,51,10):\n",
    "    \n",
    "    for depth in range(1,11):\n",
    "        \n",
    "        rf_balanced= RandomForestClassifier(random_state=12345, \n",
    "                                             n_estimators=est, \n",
    "                                             max_depth=depth, \n",
    "                                             class_weight='balanced')\n",
    "        \n",
    "        rf_balanced.fit(features_train, target_train)\n",
    "        predicted_valid = rf_balanced.predict(features_valid)\n",
    "        probabilites_valid = rf_balanced.predict_proba(features_valid)\n",
    "        probabilites_one_valid = probabilites_valid[:, 1]\n",
    "        \n",
    "        score = f1_score(target_valid, predicted_valid)\n",
    "        auc_roc = roc_auc_score(target_valid, probabilites_one_valid)\n",
    "        \n",
    "        if score > best_score:\n",
    "            \n",
    "            best_score = score\n",
    "            best_est = est\n",
    "            best_depth = depth\n",
    "            auc_score = auc_roc\n",
    "            \n",
    "print(\n",
    "    \n",
    "    \"Bosque Aleatorio con Ajuste de Clase (n_estimators = {}, max_depth = {}) | F1 = {:.6f}, AUC-ROC = {:.6f}\".format(\n",
    "        best_est, best_depth, best_score, auc_score)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresión Logística con Ajuste de Clase | F1 = 0.490598, AUC-ROC = 0.763917\n"
     ]
    }
   ],
   "source": [
    "rl_balanced = LogisticRegression(random_state=12345, solver='liblinear',  class_weight='balanced')\n",
    "\n",
    "rl_balanced.fit(features_train, target_train)\n",
    "\n",
    "predicted_valid = rl_balanced.predict(features_valid)\n",
    "\n",
    "probabilites_valid = rl_balanced.predict_proba(features_valid)\n",
    "probabilites_one_valid = probabilites_valid[:, 1]\n",
    "\n",
    "score = f1_score(target_valid, predicted_valid)\n",
    "auc_score = roc_auc_score(target_valid, probabilites_one_valid)\n",
    "\n",
    "print(\n",
    "    \n",
    "    \"Regresión Logística con Ajuste de Clase | F1 = {:.6f}, AUC-ROC = {:.6f}\".format(\n",
    "        score, auc_score)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor modelo para el ajuste de peso de clase es el Bosque Aleatorio con un F1 de 0.6272 y un AUC-ROC de 0.8469, con 40 estimadores y 10 de profundidad máxima. A continuación, se encuentra el modelo de Árbol de Decisión con un puntaje F1 de 0.5963 y AUC-ROC de 0.8310. Los dos modelos se encuentran por encima del umbral de 0.59, el modelo de árbol de decisión se ejecuta más rápido y genera un F1 alto a tan solo cinco de profundidad máxima, mientras que el modelo de bosque aleatorio tarda más tiempo en su ejecución. El modelo de regresión logística, como en los análisis anteriores, presentó el valor más bajo de F1. \n",
    "\n",
    "### Conclusiones\n",
    "\n",
    "Probamos nueve modelos diferentes en nuestro conjunto de validación, utilizando técnicas de submuestreo, sobremuestreo y ajuste de peso de clase para corregir el desbalance de clase. Los seis modelos que presentaron un F1 superior al umbral de 0.59 fueron:\n",
    "\n",
    "- Árbol de Decisión con Sobremuestreo (max_depth = 5)                      | F1 = 0.596379, AUC_ROC = 0.831024\n",
    "- Árbol de Decisión con Submuestreo (max_depth = 5)                        | F1 = 0.594320,  AUC_ROC = 0.824102\n",
    "- Árbol de Decisión con Ajuste de Clase (max_depth = 5)                    | F1 = 0.596379, AUC_ROC = 0.831024\n",
    "- Bosque Aleatorio con Sobremuestreo (n_estimators = 40, max_depth = 9)    | F1 = 0.624464, AUC-ROC = 0.854218\n",
    "- Bosque Aleatorio con Submuestreo (n_estimators = 10, max_depth = 4)      | F1 = 0.609218, AUC-ROC = 0.835469\n",
    "- Bosque Aleatorio con Ajuste de Clase (n_estimators = 40, max_depth = 10) | F1 = 0.627262, AUC-ROC = 0.846928\n",
    "\n",
    "\n",
    "Si consideramos que al aplicar nuestro modelo al conjunto de prueba, las métricas suelen disminuir, vamos a realizar la prueba final en nuestro conjunto de prueba con los tres modelos que generaron un puntaje F1 superior a 0.60: Bosque Aleatorio con Sobremuestreo, Bosque Aleatorio con Submuestreo y Bosque Aleatorio con Ajuste de Clase. Hay que recalcar que tanto el Sobremuestreo como el Ajuste de Clase generaron un puntaje F1 similar, por lo que las dos técnicas de ajuste se comportaron de manera similar en este proyecto. \n",
    "\n",
    "## Prueba Final: Calidad del modelo\n",
    "\n",
    "Procedemos a realizar la prueba final de calidad de los tres modelos que presentaron los valores más altos de F1, para esto aplicaremos las mejores métricas en nuestro conjunto de prueba `features_test` y `target_test`. En el caso del modelo de Bosque Aleatorio con Ajuste de clase, entrenaremos el modelo con nuestro conjunto de entrenamiento y utilizaremos el hiperpárametro class_weight=balanced. Para el modelo de Bosque Aleatorio con sobremuestreo entrenaremos el modelo con la muestra de sobremuestreo `features_upsampled` y `target_upsampled`; a su vez, el modelo de Bosque Aleatorio con submuestreo será entrenado con las muestras `features_downsampled` y `target_downsampled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prueba Final Bosque Aleatorio con Ajuste de Clase| F1 = 0.609844, AUC-ROC = 0.851079\n"
     ]
    }
   ],
   "source": [
    "rf_balanced_best= RandomForestClassifier(random_state=12345, \n",
    "                                             n_estimators=40, \n",
    "                                             max_depth=10, \n",
    "                                             class_weight='balanced')       \n",
    "rf_balanced_best.fit(features_train, target_train)\n",
    "\n",
    "predicted_test = rf_balanced_best.predict(features_test)\n",
    "\n",
    "probabilites_test = rf_balanced_best.predict_proba(features_test)\n",
    "probabilites_one_test = probabilites_test[:, 1]\n",
    "        \n",
    "final_score_balanced = f1_score(target_test, predicted_test)\n",
    "final_auc_balanced = roc_auc_score(target_test, probabilites_one_test)\n",
    "\n",
    "print(\n",
    "    \n",
    "    \"Prueba Final Bosque Aleatorio con Ajuste de Clase| F1 = {:.6f}, AUC-ROC = {:.6f}\".format(\n",
    "        final_score_balanced, final_auc_balanced)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prueba Final Bosque Aleatorio Sobremuestreo| F1 = 0.606250, AUC-ROC = 0.852275\n"
     ]
    }
   ],
   "source": [
    "rf_upsampled_best= RandomForestClassifier(random_state=12345, n_estimators=40, max_depth=9)\n",
    "        \n",
    "rf_upsampled_best.fit(features_upsampled, target_upsampled)\n",
    "\n",
    "predicted_test = rf_upsampled_best.predict(features_test)\n",
    "\n",
    "probabilites_test = rf_upsampled_best.predict_proba(features_test)\n",
    "probabilites_one_test = probabilites_test[:, 1]\n",
    "        \n",
    "final_score_upsampled = f1_score(target_test, predicted_test)\n",
    "final_auc_upsampled = roc_auc_score(target_test, probabilites_one_test)\n",
    "\n",
    "print(\n",
    "    \n",
    "    \"Prueba Final Bosque Aleatorio Sobremuestreo| F1 = {:.6f}, AUC-ROC = {:.6f}\".format(\n",
    "        final_score_upsampled, final_auc_upsampled)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prueba Final Bosque Aleatorio Submuestreo| F1 = 0.581818, AUC-ROC = 0.833994\n"
     ]
    }
   ],
   "source": [
    "rf_downsampled_best= RandomForestClassifier(random_state=12345, n_estimators=10, max_depth=4)\n",
    "        \n",
    "rf_downsampled_best.fit(features_downsampled, target_downsampled)\n",
    "\n",
    "predicted_test = rf_downsampled_best.predict(features_test)\n",
    "\n",
    "probabilites_test = rf_downsampled_best.predict_proba(features_test)\n",
    "probabilites_one_test = probabilites_test[:, 1]\n",
    "        \n",
    "final_score_upsampled = f1_score(target_test, predicted_test)\n",
    "final_auc_upsampled = roc_auc_score(target_test, probabilites_one_test)\n",
    "\n",
    "print(\n",
    "    \n",
    "    \"Prueba Final Bosque Aleatorio Submuestreo| F1 = {:.6f}, AUC-ROC = {:.6f}\".format(\n",
    "        final_score_upsampled, final_auc_upsampled)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el modelo de Bosque Aleatorio con Ajuste de Clase se obtuvo el puntaje F1 de 0.6098 y para el modelo de Bosque Aleatorio con Sobremuestreo se obtuvo un F1 de 0.6062. Los dos modelos se encuentran por encima del umbral de 0.59, y el valor de AUC-ROC se encuentra alrededor de 0.85 para ambos modelos. En el caso del modelo de Bosque Aleatorio con submuestreo, al aplicarlo a nuestro conjunto de prueba el puntaje F1 disminuyó a 0.5818, este valor se encuentra por debajo del umbral establecido, así que descartamos este modelo. \n",
    "\n",
    "En este caso, dado que la métrica F1 es similar entre los dos primeros modelos, vamos a quedarnos con el modelo de Bosque Aleatorio con Ajuste de Clase como nuestro modelo predictivo ya que presenta un F1 ligeramente superior al modelo con sobremuestreo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de Cordura\n",
    "\n",
    "Una vez establecido nuestro modelo predictivo de Bosque Aleatorio con Ajuste de Clase como el más propicio para predecir la tendencia a la deserción de los clientes de Beta Bank, vamos a realizar un último análisis conocido como Prueba de Cordura que buscará problemas en las clasificicación del modelo comparando las predicciones en el conjunto de prueba con la aleatoriedad. Para esto vamos a generar una serie que será rellenada con valores aleatorios de 0 ó 1 y la guardaremos en la variable `predictions_random`. Para construir nuestro objeto Series vamos a utilizar la función pd.Series de Pandas y pasaremos como tamaño del objetivo valores aleatorios de 0 ó 1 a través de la función random.choice de numpy, estableceremos el tamaño de nuestro array de valores igual al tamaño de `target_test`. A su vez, estableceremos como índice del objeto Series los índices registrados en `target_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1007\n",
       "0     993\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Establecemos el valor que se establecerá como semilla para el generador de números pseudoaleatorios\n",
    "np.random.seed(54321)\n",
    "\n",
    "#Construimos nuestro objeto Series de valores aleatorios 0 ó 1\n",
    "predictions_random =  pd.Series(np.random.choice([0, 1], size=len(target_test)), index=target_test.index)\n",
    "\n",
    "#Comprobamos los valores únicos del objeto Series llamando a value_counts\n",
    "predictions_random.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 aleatoriedad: 0.2867132867132867\n",
      "F1 mejor modelo predictivo: 0.6098439375750301\n"
     ]
    }
   ],
   "source": [
    "print('F1 aleatoriedad:', f1_score(target_test, predictions_random))\n",
    "print('F1 mejor modelo predictivo:', final_score_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo presenta un F1 superior al modelo aleatoriamente rellenado con 0 y 1, ahora vamos a realizar un última prueba construyendo un curva ROC, que también nos permitirá comprobar el rendimiento del modelo de clasificación.\n",
    "\n",
    "Una curva ROC nos permite establecer que tan bueno es un modelo al distinguir entre dos clases, un buen modelo podrá distinguir entre los dos, mientras que un modelo pobre no podrá realizar una correcta predicción de clases. Esta curva se construye en base a la tasa de verdaderos positivos y la tasa de falsos positivos en diferentes umbrales del modelo. A su vez, se compara nuestra curva con un modelo que responde aleatoriamente, el cual será representado como un línea diagonal que va desde la esquina inferior izquierda hasta la esquina superior derecha. Mientras más alta sea la curva, mejor será la calidad del modelo.\n",
    "\n",
    "Para construir esta curva vamos a utilizar la función `roc_curve` de Scikit-Learn que nos permitirá obtener la tasa de verdaderos positivos, tasa de falsos positivos y los umbrales al pasar como argumentos `target_test` y `probabilities_one_test`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Área Bajo la Curva ROC para el modelo final 0.8510788206952482\n"
     ]
    }
   ],
   "source": [
    "# Obtenermos las predicciones de probabilidades para el conjunto de prueba\n",
    "probabilities_test = rf_balanced_best.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "\n",
    "# Llamamos a la función roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(target_test, probabilities_one_test)\n",
    "\n",
    "# Trazamos el gráfico\n",
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "# Curva ROC de nuestr modelo predictivo\n",
    "plt.plot(fpr, tpr, label= 'Modelo de Alta Calidad')\n",
    "\n",
    "# Curva ROC para modelo aleatorio (parece una línea recta)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Modelo Aleatorio')\n",
    "plt.legend(loc = 'lower right')\n",
    "\n",
    "# Establecemos el límite para los ejes de 0 a 1 \n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "\n",
    "# Nombramos los ejes y agregamos un encabezado\n",
    "plt.xlabel('Tasa de falsos positivos')\n",
    "plt.ylabel('Tasa de verdaderos positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.show()\n",
    "\n",
    "print('Área Bajo la Curva ROC para el modelo final', final_auc_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La curva ROC para nuestro modelo final se encuentra por encima de la línea que representa un modelo aleatorio, además la curva es alta, por lo que el modelo es bueno en distinguir entre las dos categorías. A su vez, el valor de AUC-ROC obtenido fue de 0.8510, superior al valor 0.5 que se asigna a modelos aleatorios, pudiendo determinar que nuestro modelo predictivo es mejor que la aleatoriedad, pasando nuevamente la prueba de cordura final. \n",
    "\n",
    "## Conclusiones\n",
    "\n",
    "\n",
    "**Preprocesamiento de datos**\n",
    "\n",
    "1. Previo a la construcción del modelo se eliminaron tres variables que no ayudarían a crear un modelo predictivo, ya que contenían información referente al ID del usuario o su apellido. A su vez, se corrigió el nombre de las columnas, transformándolas a minúsculas, todo acorde con las normas de buen estilo en programación.\n",
    "2. Se registraron valores ausentes en la variable `tenure` los cuales fueron reemplazados a través de las predicciones realizadas por un modelo de regresión lineal. No se utilizó la media, mediana o cero, ya que esto afectaría la distribución de nuestro datos, influyendo en el modelo.\n",
    "\n",
    "**Construcción de modelo predictivo**\n",
    "\n",
    "1. Se estableció como objetivo del modelo la variable `existed` y las once variables restantes se utilizaron como características del modelo. Las características categóricas fueron codificadas a través de One-Hot Encoding, mientras que las características numéricas fueron estandarizadas a través de la técnica de escalado.\n",
    "2. Se dividió el dataset en tres conjuntos: entrenamiento, validación y prueba, en una propoción 3:1:1, y se establecieron las características y objetivos de cada grupo de datos. \n",
    "3. Nuestro objetivo fue de tipo clasificatorio, por lo que se comprobó si existía un desequilibrio entra las clases 1 y 0. Al confirmarse esto, se decidió entrenar modelos con y sin desequilibrio de clases. Para esto se utilizaron tres algoritmos de aprendizaje: Árbol de Decisión, Bosque Aleatorio y Regresión Logística. \n",
    "4. Ninguno de los modelos entrenados sin desbalance de clases alcanzó el umbral mínimo de 0.59, ya que estos modelos no son capaces de detectar valores verdaderos negativos, que son los que presentaron una mayor proporción. \n",
    "5. Los modelos que consideraron el desbalance de clases fueron entrenados con submuestreo, sobremuestreo y ajuste de peso de clase. Se registraron puntajes F1 superiores a 0.59 para los modelos de Bosque Aleatorio y Árbol de Decisión con submuestreo, sobremuestreo y ajuste de clase. Se decidió analizar la calidad del modelo en nuestro conjunto de prueba con el modelo de Bosque Aleatorio tanto en submuestreo, sobremuestreo y ajuste de peso de clase.  \n",
    "\n",
    "**Modelo Predictivo Final**\n",
    "\n",
    "Se concluye que el mejor modelo para predecir correctamente la deserción de clientes de Beta Bank es el modelo de Bosque Aleatorio (n_estimators = 40, max_depth = 10) con ajuste de peso de clase. Este modelo alcanzó un puntaje F1 de 0.6098, que se encuentra por encima del umbral mínimo de 0.59. Así mismo, el modelo alcanzó un AUC-ROC de 0.8510, lo que indica que hay un 85% de probabilidad de que distinga correctamente entre aquellos clientes que abandonarán o no la entidad bancaria. Además, este valor se encuentra por encima del valor AUC-ROC de 0.5 para un modelo aleatorio, por lo que nuestro modelo rinde mejor que la aleatoriedad. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "298.075px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
